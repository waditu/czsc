"""
ä»·æ ¼æ•æ„Ÿæ€§åˆ†ææ¨¡å—

ç”¨äºåˆ†æç­–ç•¥å¯¹æ‰§è¡Œä»·æ ¼çš„æ•æ„Ÿæ€§ï¼Œé€šè¿‡å¯¹æ¯”ä¸åŒäº¤æ˜“ä»·æ ¼çš„å›æµ‹ç»“æœæ¥è¯„ä¼°ä»·æ ¼æ‰§è¡Œå¯¹ç­–ç•¥æ€§èƒ½çš„å½±å“ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. ç´¯è®¡æ”¶ç›Šæ›²çº¿å±•ç¤º
2. ä»·æ ¼æ•æ„Ÿæ€§åˆ†æ
3. åˆ†æç»“æœæ‘˜è¦

ä½œè€…: czsc
"""

import pandas as pd
import streamlit as st
from loguru import logger
from typing import Optional, Tuple

from .base import safe_import_weight_backtest, apply_stats_style
from .returns import show_cumulative_returns


def show_price_sensitive(df: pd.DataFrame, 
                        fee: float = 2.0, 
                        digits: int = 2, 
                        weight_type: str = "ts", 
                        n_jobs: int = 1, 
                        **kwargs) -> Optional[Tuple[pd.DataFrame, pd.DataFrame]]:
    """ä»·æ ¼æ•æ„Ÿæ€§åˆ†æç»„ä»¶
    
    åˆ†æç­–ç•¥å¯¹æ‰§è¡Œä»·æ ¼çš„æ•æ„Ÿæ€§ï¼Œé€šè¿‡å¯¹æ¯”ä¸åŒäº¤æ˜“ä»·æ ¼çš„å›æµ‹ç»“æœæ¥è¯„ä¼°ä»·æ ¼æ‰§è¡Œå¯¹ç­–ç•¥æ€§èƒ½çš„å½±å“ã€‚
    
    å‚æ•°:
        df: åŒ…å«ä»¥ä¸‹å¿…è¦åˆ—çš„æ•°æ®æ¡†ï¼š
            - symbol: åˆçº¦ä»£ç 
            - dt: æ—¥æœŸæ—¶é—´
            - weight: ä»“ä½æƒé‡
            - price: åŸºå‡†ä»·æ ¼
            - TP*: ä»¥TPå¼€å¤´çš„äº¤æ˜“ä»·æ ¼åˆ—ï¼ˆå¦‚TP_open, TP_highç­‰ï¼‰
        fee: å•è¾¹è´¹ç‡ï¼ˆBPï¼‰ï¼Œé»˜è®¤2.0
        digits: å°æ•°ä½æ•°ï¼Œé»˜è®¤2
        weight_type: æƒé‡ç±»å‹ï¼Œå¯é€‰ "ts" æˆ– "cs"ï¼Œé»˜è®¤ "ts"
        n_jobs: å¹¶è¡Œæ•°ï¼Œé»˜è®¤1
        **kwargs: å…¶ä»–å‚æ•°
            - title_prefix: æ ‡é¢˜å‰ç¼€ï¼Œé»˜è®¤ä¸ºç©º
            - show_detailed_stats: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ï¼Œé»˜è®¤False
    
    è¿”å›:
        tuple: (dfr, dfd) åˆ†åˆ«ä¸ºç»Ÿè®¡ç»“æœDataFrameå’Œæ—¥æ”¶ç›Šç‡DataFrameï¼Œå¤±è´¥æ—¶è¿”å›None
    
    ç¤ºä¾‹:
        >>> # åŸºæœ¬ç”¨æ³•
        >>> dfr, dfd = show_price_sensitive(df, fee=2.0, digits=2)
        
        >>> # è‡ªå®šä¹‰å‚æ•°
        >>> dfr, dfd = show_price_sensitive(
        ...     df, 
        ...     fee=1.5, 
        ...     digits=3, 
        ...     weight_type="cs",
        ...     n_jobs=4,
        ...     title_prefix="ç­–ç•¥A - ",
        ...     show_detailed_stats=True
        ... )
    """
    from czsc.eda import cal_yearly_days
    
    # å‚æ•°å¤„ç†
    title_prefix = kwargs.get("title_prefix", "")
    show_detailed_stats = kwargs.get("show_detailed_stats", False)
    
    # æ•°æ®éªŒè¯
    required_cols = ["symbol", "dt", "weight", "price"]
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        error_msg = f"ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_cols}"
        st.error(error_msg)
        logger.error(f"æ•°æ®æ£€æŸ¥å¤±è´¥ï¼Œ{error_msg}")
        return None
    
    # æŸ¥æ‰¾äº¤æ˜“ä»·æ ¼åˆ—
    tp_cols = [x for x in df.columns if x.startswith("TP")]
    if not tp_cols:
        error_msg = "æ²¡æœ‰æ‰¾åˆ°äº¤æ˜“ä»·æ ¼åˆ—ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶ï¼›äº¤æ˜“ä»·åˆ—åå¿…é¡»ä»¥ TP å¼€å¤´"
        st.error(error_msg)
        logger.error("æœªæ‰¾åˆ°ä»¥TPå¼€å¤´çš„äº¤æ˜“ä»·æ ¼åˆ—")
        return None
    
    logger.info(f"æ‰¾åˆ° {len(tp_cols)} ä¸ªäº¤æ˜“ä»·æ ¼åˆ—: {tp_cols}")
    
    # è®¡ç®—å¹´åŒ–å¤©æ•°
    try:
        yearly_days = cal_yearly_days(dts=df["dt"].unique().tolist())
        logger.info(f"è®¡ç®—å¾—åˆ°å¹´åŒ–å¤©æ•°: {yearly_days}")
    except Exception as e:
        error_msg = f"è®¡ç®—å¹´åŒ–å¤©æ•°å¤±è´¥: {e}"
        st.error(error_msg)
        logger.error(error_msg)
        return None
    
    # è·å–WeightBacktestç±»
    WeightBacktest = safe_import_weight_backtest()
    if WeightBacktest is None:
        st.error("æ— æ³•å¯¼å…¥å›æµ‹ç±»ï¼Œè¯·æ£€æŸ¥ czsc å®‰è£…")
        return None
    
    # ç»“æœæ”¶é›†
    c1 = st.container(border=True)
    rows = []
    dfd = pd.DataFrame()
    
    # åˆ›å»ºè¿›åº¦æ¡
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # é€ä¸ªå¤„ç†äº¤æ˜“ä»·æ ¼
    for i, tp_col in enumerate(tp_cols):
        try:
            progress = (i + 1) / len(tp_cols)
            progress_bar.progress(progress)
            status_text.text(f"æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{len(tp_cols)} ä¸ªäº¤æ˜“ä»·æ ¼: {tp_col}")
            
            logger.info(f"æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{len(tp_cols)} ä¸ªäº¤æ˜“ä»·æ ¼: {tp_col}")
            
            # å‡†å¤‡æ•°æ®
            df_temp = df.copy()
            df_temp[tp_col] = df_temp[tp_col].fillna(df_temp["price"])
            dfw = df_temp[["symbol", "dt", 'weight', tp_col]].copy()
            dfw.rename(columns={tp_col: "price"}, inplace=True)

            # åˆ›å»ºå›æµ‹å®ä¾‹
            wb = WeightBacktest(
                dfw=dfw,
                digits=digits,
                fee_rate=fee/10000,
                weight_type=weight_type,
                n_jobs=n_jobs,
                yearly_days=yearly_days
            )
            
            # è·å–æ—¥æ”¶ç›Šç‡
            daily = wb.daily_return.copy()
            daily.rename(columns={"total": tp_col}, inplace=True)
            
            if dfd.empty:
                dfd = daily[['date', tp_col]].copy()
            else:
                dfd = pd.merge(dfd, daily[['date', tp_col]], on='date', how='outer')

            # æ”¶é›†ç»Ÿè®¡ç»“æœ
            res = {"äº¤æ˜“ä»·æ ¼": tp_col}
            res.update(wb.stats)
            rows.append(res)
            
        except Exception as e:
            warning_msg = f"å¤„ç†äº¤æ˜“ä»·æ ¼ {tp_col} æ—¶å‡ºé”™: {e}"
            st.warning(warning_msg)
            logger.error(warning_msg)
            continue
    
    # æ¸…é™¤è¿›åº¦æ¡
    progress_bar.empty()
    status_text.empty()
    
    if not rows:
        st.error("æ‰€æœ‰äº¤æ˜“ä»·æ ¼å¤„ç†å¤±è´¥ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š")
        return None


    # æ˜¾ç¤ºç»“æœ
    with c1:
        st.markdown(f"##### :red[{title_prefix}ä¸åŒäº¤æ˜“ä»·æ ¼å›æµ‹æ ¸å¿ƒæŒ‡æ ‡å¯¹æ¯”]")
        dfr = pd.DataFrame(rows)

        # æ•æ„Ÿæ€§è¯„ä¼°
        if len(dfr) > 1 and "å¹´åŒ–" in dfr.columns:
            _show_sensitivity_assessment(dfr)

        # é€‰æ‹©æ˜¾ç¤ºåˆ—
        if show_detailed_stats:
            display_cols = ['äº¤æ˜“ä»·æ ¼', "å¼€å§‹æ—¥æœŸ", "ç»“æŸæ—¥æœŸ", "ç»å¯¹æ”¶ç›Š", "å¹´åŒ–", "å¹´åŒ–æ³¢åŠ¨ç‡", 
                           "å¤æ™®", "æœ€å¤§å›æ’¤", "å¡ç›", "æ—¥èƒœç‡", "æ—¥ç›ˆäºæ¯”", "äº¤æ˜“èƒœç‡", 
                           "å•ç¬”æ”¶ç›Š", "æŒä»“Kçº¿æ•°", "æŒä»“å¤©æ•°", "å¤šå¤´å æ¯”", "ç©ºå¤´å æ¯”"]
        else:
            display_cols = ['äº¤æ˜“ä»·æ ¼', "å¼€å§‹æ—¥æœŸ", "ç»“æŸæ—¥æœŸ", "ç»å¯¹æ”¶ç›Š", "å¹´åŒ–", "å¹´åŒ–æ³¢åŠ¨ç‡", 
                           "å¤æ™®", "æœ€å¤§å›æ’¤", "å¡ç›", "äº¤æ˜“èƒœç‡", "å•ç¬”æ”¶ç›Š", "æŒä»“Kçº¿æ•°"]
        
        # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½å­˜åœ¨
        available_cols = [col for col in display_cols if col in dfr.columns]
        dfr_display = dfr[available_cols].copy()
        
        # åº”ç”¨æ ·å¼
        dfr_styled = apply_stats_style(dfr_display)
        st.dataframe(dfr_styled, use_container_width=True)
    
    # ç´¯è®¡æ”¶ç›Šå¯¹æ¯”
    c2 = st.container(border=True)
    with c2:
        st.markdown(f"##### :red[{title_prefix}ä¸åŒäº¤æ˜“ä»·æ ¼å›æµ‹ç´¯è®¡æ”¶ç›Šå¯¹æ¯”]")
        
        if not dfd.empty:
            dfd_plot = dfd.copy()
            dfd_plot['date'] = pd.to_datetime(dfd_plot['date'])
            dfd_plot.set_index("date", inplace=True)
            
            show_cumulative_returns(
                dfd_plot, 
                fig_title=f"{title_prefix}ä¸åŒäº¤æ˜“ä»·æ ¼ç´¯è®¡æ”¶ç›Šå¯¹æ¯”"
            )
        else:
            st.warning("æ²¡æœ‰æœ‰æ•ˆçš„æ”¶ç›Šç‡æ•°æ®ç”¨äºç»˜åˆ¶å›¾è¡¨")
    
    logger.info(f"ä»·æ ¼æ•æ„Ÿæ€§åˆ†æå®Œæˆï¼Œå…±å¤„ç† {len(rows)} ä¸ªäº¤æ˜“ä»·æ ¼")
    return dfr, dfd


def _show_sensitivity_assessment(dfr: pd.DataFrame) -> None:
    """æ˜¾ç¤ºæ•æ„Ÿæ€§è¯„ä¼°"""
    annual_returns = dfr["å¹´åŒ–"]
    sensitivity_score = (annual_returns.max() - annual_returns.min()) / annual_returns.mean()
    
    st.markdown("**æ•æ„Ÿæ€§è¯„ä¼°ï¼š**")
    if sensitivity_score < 0.1:
        st.success(f"ğŸŸ¢ ç­–ç•¥å¯¹ä»·æ ¼æ‰§è¡Œä¸æ•æ„Ÿ (æ•æ„Ÿåº¦: {sensitivity_score:.2%})")
    elif sensitivity_score < 0.3:
        st.warning(f"ğŸŸ¡ ç­–ç•¥å¯¹ä»·æ ¼æ‰§è¡Œä¸­ç­‰æ•æ„Ÿ (æ•æ„Ÿåº¦: {sensitivity_score:.2%})")
    else:
        st.error(f"ğŸ”´ ç­–ç•¥å¯¹ä»·æ ¼æ‰§è¡Œé«˜åº¦æ•æ„Ÿ (æ•æ„Ÿåº¦: {sensitivity_score:.2%})")


# æ”¯æŒçš„å‡½æ•°åˆ—è¡¨
__all__ = [
    'show_price_sensitive', 
] 