"""
ä»·æ ¼æ•æ„Ÿæ€§åˆ†æ Streamlit ç»„ä»¶

ç”¨äºåˆ†æç­–ç•¥å¯¹æ‰§è¡Œä»·æ ¼çš„æ•æ„Ÿæ€§ï¼Œé€šè¿‡å¯¹æ¯”ä¸åŒäº¤æ˜“ä»·æ ¼çš„å›æµ‹ç»“æœæ¥è¯„ä¼°ä»·æ ¼æ‰§è¡Œå¯¹ç­–ç•¥æ€§èƒ½çš„å½±å“ã€‚

ä½œè€…: Assistant
åˆ›å»ºæ—¶é—´: 2024å¹´
"""

import pandas as pd
import streamlit as st
import plotly.express as px
from loguru import logger
import czsc


def show_cumulative_returns(df, **kwargs):
    """å±•ç¤ºç´¯è®¡æ”¶ç›Šæ›²çº¿
    
    :param df: pd.DataFrame, æ•°æ®æºï¼Œindex ä¸ºæ—¥æœŸï¼Œcolumns ä¸ºå¯¹åº”ä¸Šä¸€ä¸ªæ—¥æœŸè‡³ä»Šçš„æ”¶ç›Š
    :param kwargs: dict, å¯é€‰å‚æ•°
        - fig_title: str, å›¾è¡¨æ ‡é¢˜ï¼Œé»˜è®¤ "ç´¯è®¡æ”¶ç›Š"
        - legend_only_cols: list, ä»…åœ¨å›¾ä¾‹ä¸­æ˜¾ç¤ºçš„åˆ—ååˆ—è¡¨
    """
    assert df.index.dtype == "datetime64[ns]", "indexå¿…é¡»æ˜¯datetime64[ns]ç±»å‹, è¯·å…ˆä½¿ç”¨ pd.to_datetime è¿›è¡Œè½¬æ¢"
    assert df.index.is_unique, "df çš„ç´¢å¼•å¿…é¡»å”¯ä¸€"
    assert df.index.is_monotonic_increasing, "df çš„ç´¢å¼•å¿…é¡»å•è°ƒé€’å¢"

    fig_title = kwargs.get("fig_title", "ç´¯è®¡æ”¶ç›Š")
    df = df.cumsum()
    fig = px.line(df, y=df.columns.to_list(), title=fig_title)
    fig.update_xaxes(title="")

    # æ·»åŠ æ¯å¹´çš„å¼€å§‹ç¬¬ä¸€ä¸ªæ—¥æœŸçš„ç«–çº¿
    for year in range(df.index.year.min(), df.index.year.max() + 1):
        first_date = df[df.index.year == year].index.min()
        fig.add_vline(x=first_date, line_dash="dash", line_color="red")

    for col in kwargs.get("legend_only_cols", []):
        fig.update_traces(visible="legendonly", selector=dict(name=col))
        
    # å°† legend ç§»åŠ¨åˆ°å›¾è¡¨çš„åº•éƒ¨å¹¶æ°´å¹³å±…ä¸­æ˜¾ç¤º
    fig.update_layout(legend=dict(
        orientation="h",
        y=-0.1,
        xanchor="center",
        x=0.5
    ), margin=dict(l=0, r=0, b=0))
    
    st.plotly_chart(fig, use_container_width=True)


def show_price_sensitive(df, fee=2.0, digits=2, weight_type="ts", n_jobs=1, **kwargs):
    """ä»·æ ¼æ•æ„Ÿæ€§åˆ†æç»„ä»¶
    
    ç”¨äºåˆ†æç­–ç•¥å¯¹æ‰§è¡Œä»·æ ¼çš„æ•æ„Ÿæ€§ï¼Œé€šè¿‡å¯¹æ¯”ä¸åŒäº¤æ˜“ä»·æ ¼çš„å›æµ‹ç»“æœæ¥è¯„ä¼°ä»·æ ¼æ‰§è¡Œå¯¹ç­–ç•¥æ€§èƒ½çš„å½±å“ã€‚
    
    :param df: pd.DataFrame, åŒ…å«ä»¥ä¸‹å¿…è¦åˆ—çš„æ•°æ®æ¡†ï¼š
        - symbol: str, åˆçº¦ä»£ç 
        - dt: datetime, æ—¥æœŸæ—¶é—´
        - weight: float, ä»“ä½æƒé‡
        - price: float, åŸºå‡†ä»·æ ¼
        - TP*: float, ä»¥TPå¼€å¤´çš„äº¤æ˜“ä»·æ ¼åˆ—ï¼ˆå¦‚TP_open, TP_highç­‰ï¼‰
    :param fee: float, å•è¾¹è´¹ç‡ï¼ˆBPï¼‰ï¼Œé»˜è®¤2.0
    :param digits: int, å°æ•°ä½æ•°ï¼Œé»˜è®¤2
    :param weight_type: str, æƒé‡ç±»å‹ï¼Œå¯é€‰ "ts" æˆ– "cs"ï¼Œé»˜è®¤ "ts"
    :param n_jobs: int, å¹¶è¡Œæ•°ï¼Œé»˜è®¤1
    :param kwargs: dict, å…¶ä»–å‚æ•°
        - title_prefix: str, æ ‡é¢˜å‰ç¼€ï¼Œé»˜è®¤ä¸ºç©º
        - show_detailed_stats: bool, æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ï¼Œé»˜è®¤False
        - export_results: bool, æ˜¯å¦å¯¼å‡ºç»“æœï¼Œé»˜è®¤False
    
    :return: tuple, (dfr, dfd) åˆ†åˆ«ä¸ºç»Ÿè®¡ç»“æœDataFrameå’Œæ—¥æ”¶ç›Šç‡DataFrameï¼Œå¤±è´¥æ—¶è¿”å›None
    
    Examples:
    --------
    >>> # åŸºæœ¬ç”¨æ³•
    >>> dfr, dfd = show_price_sensitive(df, fee=2.0, digits=2)
    
    >>> # è‡ªå®šä¹‰å‚æ•°
    >>> dfr, dfd = show_price_sensitive(
    ...     df, 
    ...     fee=1.5, 
    ...     digits=3, 
    ...     weight_type="cs",
    ...     n_jobs=4,
    ...     title_prefix="ç­–ç•¥A - ",
    ...     show_detailed_stats=True
    ... )
    """
    from czsc.eda import cal_yearly_days
    
    # å‚æ•°å¤„ç†
    title_prefix = kwargs.get("title_prefix", "")
    show_detailed_stats = kwargs.get("show_detailed_stats", False)
    export_results = kwargs.get("export_results", False)
    
    # æ£€æŸ¥å¿…è¦çš„åˆ—
    required_cols = ["symbol", "dt", "weight", "price"]
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        st.error(f"ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_cols}")
        logger.error(f"æ•°æ®æ£€æŸ¥å¤±è´¥ï¼Œç¼ºå°‘å¿…è¦çš„åˆ—: {missing_cols}")
        return None
    
    # æŸ¥æ‰¾äº¤æ˜“ä»·æ ¼åˆ—
    tp_cols = [x for x in df.columns if x.startswith("TP")]
    if len(tp_cols) == 0:
        st.error("æ²¡æœ‰æ‰¾åˆ°äº¤æ˜“ä»·æ ¼åˆ—ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶; äº¤æ˜“ä»·åˆ—åå¿…é¡»ä»¥ TP å¼€å¤´")
        logger.error("æœªæ‰¾åˆ°ä»¥TPå¼€å¤´çš„äº¤æ˜“ä»·æ ¼åˆ—")
        return None
    
    logger.info(f"æ‰¾åˆ° {len(tp_cols)} ä¸ªäº¤æ˜“ä»·æ ¼åˆ—: {tp_cols}")
    
    try:
        yearly_days = cal_yearly_days(dts=df["dt"].unique().tolist())
        logger.info(f"è®¡ç®—å¾—åˆ°å¹´åŒ–å¤©æ•°: {yearly_days}")
    except Exception as e:
        st.error(f"è®¡ç®—å¹´åŒ–å¤©æ•°å¤±è´¥: {e}")
        logger.error(f"è®¡ç®—å¹´åŒ–å¤©æ•°å¤±è´¥: {e}")
        return None
    
    # æ ¸å¿ƒæŒ‡æ ‡å¯¹æ¯”å®¹å™¨
    c1 = st.container(border=True)
    rows = []
    dfd = pd.DataFrame()
    
    # åˆ›å»ºè¿›åº¦æ¡
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, tp_col in enumerate(tp_cols):
        try:
            progress = (i + 1) / len(tp_cols)
            progress_bar.progress(progress)
            status_text.text(f"æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{len(tp_cols)} ä¸ªäº¤æ˜“ä»·æ ¼: {tp_col}")
            
            logger.info(f"æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{len(tp_cols)} ä¸ªäº¤æ˜“ä»·æ ¼: {tp_col}")
            
            # å‡†å¤‡æ•°æ®
            df_temp = df.copy()
            df_temp[tp_col] = df_temp[tp_col].fillna(df_temp["price"])
            dfw = df_temp[["symbol", "dt", 'weight', tp_col]].copy()
            dfw.rename(columns={tp_col: "price"}, inplace=True)

            # åˆ›å»ºå›æµ‹å®ä¾‹
            wb = czsc.WeightBacktest(
                dfw=dfw,
                digits=digits,
                fee_rate=fee/10000,
                weight_type=weight_type,
                n_jobs=n_jobs,
                yearly_days=yearly_days
            )
            
            # è·å–æ—¥æ”¶ç›Šç‡
            daily = wb.daily_return.copy()
            daily.rename(columns={"total": tp_col}, inplace=True)
            
            if dfd.empty:
                dfd = daily[['date', tp_col]].copy()
            else:
                dfd = pd.merge(dfd, daily[['date', tp_col]], on='date', how='outer')

            # æ”¶é›†ç»Ÿè®¡ç»“æœ
            res = {"äº¤æ˜“ä»·æ ¼": tp_col}
            res.update(wb.stats)
            rows.append(res)
            
        except Exception as e:
            st.warning(f"å¤„ç†äº¤æ˜“ä»·æ ¼ {tp_col} æ—¶å‡ºé”™: {e}")
            logger.error(f"å¤„ç†äº¤æ˜“ä»·æ ¼ {tp_col} æ—¶å‡ºé”™: {e}")
            continue
    
    # æ¸…é™¤è¿›åº¦æ¡
    progress_bar.empty()
    status_text.empty()
    
    if not rows:
        st.error("æ‰€æœ‰äº¤æ˜“ä»·æ ¼å¤„ç†å¤±è´¥ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š")
        return None

    with c1:
        st.markdown(f"##### :red[{title_prefix}ä¸åŒäº¤æ˜“ä»·æ ¼å›æµ‹æ ¸å¿ƒæŒ‡æ ‡å¯¹æ¯”]")
        dfr = pd.DataFrame(rows)

        # é€‰æ‹©å…³é”®æŒ‡æ ‡å±•ç¤º
        if show_detailed_stats:
            # æ˜¾ç¤ºè¯¦ç»†æŒ‡æ ‡
            display_cols = ['äº¤æ˜“ä»·æ ¼', "å¼€å§‹æ—¥æœŸ", "ç»“æŸæ—¥æœŸ", "ç»å¯¹æ”¶ç›Š", "å¹´åŒ–", "å¹´åŒ–æ³¢åŠ¨ç‡", 
                           "å¤æ™®", "æœ€å¤§å›æ’¤", "å¡ç›", "æ—¥èƒœç‡", "æ—¥ç›ˆäºæ¯”", "äº¤æ˜“èƒœç‡", 
                           "å•ç¬”æ”¶ç›Š", "æŒä»“Kçº¿æ•°", "æŒä»“å¤©æ•°", "å¤šå¤´å æ¯”", "ç©ºå¤´å æ¯”"]
        else:
            # æ˜¾ç¤ºæ ¸å¿ƒæŒ‡æ ‡
            display_cols = ['äº¤æ˜“ä»·æ ¼', "å¼€å§‹æ—¥æœŸ", "ç»“æŸæ—¥æœŸ", "ç»å¯¹æ”¶ç›Š", "å¹´åŒ–", "å¹´åŒ–æ³¢åŠ¨ç‡", 
                           "å¤æ™®", "æœ€å¤§å›æ’¤", "å¡ç›", "äº¤æ˜“èƒœç‡", "å•ç¬”æ”¶ç›Š", "æŒä»“Kçº¿æ•°"]
        
        # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½å­˜åœ¨
        available_cols = [col for col in display_cols if col in dfr.columns]
        dfr_display = dfr[available_cols].copy()
        
        # åº”ç”¨æ ·å¼
        style_subset_positive = [col for col in ["ç»å¯¹æ”¶ç›Š", "äº¤æ˜“èƒœç‡", "å¹´åŒ–", "å¤æ™®", "å¡ç›", "å•ç¬”æ”¶ç›Š", "æ—¥èƒœç‡"] if col in available_cols]
        style_subset_negative = [col for col in ["å¹´åŒ–æ³¢åŠ¨ç‡", "æœ€å¤§å›æ’¤"] if col in available_cols]
        
        dfr_styled = dfr_display.style
        
        if style_subset_positive:
            dfr_styled = dfr_styled.background_gradient(cmap="RdYlGn_r", subset=style_subset_positive)
        if style_subset_negative:
            dfr_styled = dfr_styled.background_gradient(cmap="RdYlGn", subset=style_subset_negative)
        
        # æ ¼å¼åŒ–æ•°å€¼
        format_dict = {}
        for col in available_cols:
            if col in ["ç»å¯¹æ”¶ç›Š", "å¹´åŒ–", "å¹´åŒ–æ³¢åŠ¨ç‡", "æœ€å¤§å›æ’¤", "äº¤æ˜“èƒœç‡", "æ—¥èƒœç‡", "å¤šå¤´å æ¯”", "ç©ºå¤´å æ¯”"]:
                format_dict[col] = "{:.2%}"
            elif col in ["å¤æ™®", "å¡ç›", "å•ç¬”æ”¶ç›Š", "æ—¥ç›ˆäºæ¯”"]:
                format_dict[col] = "{:.2f}"
            elif col in ["æŒä»“Kçº¿æ•°", "æŒä»“å¤©æ•°"]:
                format_dict[col] = "{:.0f}"
        
        if format_dict:
            dfr_styled = dfr_styled.format(format_dict)
        
        st.dataframe(dfr_styled, use_container_width=True)
        
        # å¯¼å‡ºç»“æœé€‰é¡¹
        if export_results:
            col1, col2 = st.columns(2)
            with col1:
                if st.button("å¯¼å‡ºç»Ÿè®¡ç»“æœä¸ºCSV"):
                    csv = dfr.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label="ä¸‹è½½ç»Ÿè®¡ç»“æœ",
                        data=csv,
                        file_name=f"price_sensitivity_stats_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )
            
            with col2:
                if st.button("å¯¼å‡ºæ—¥æ”¶ç›Šç‡ä¸ºCSV"):
                    csv = dfd.to_csv(encoding='utf-8-sig')
                    st.download_button(
                        label="ä¸‹è½½æ—¥æ”¶ç›Šç‡",
                        data=csv,
                        file_name=f"price_sensitivity_returns_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )
    
    # ç´¯è®¡æ”¶ç›Šå¯¹æ¯”å®¹å™¨
    c2 = st.container(border=True)
    with c2:
        st.markdown(f"##### :red[{title_prefix}ä¸åŒäº¤æ˜“ä»·æ ¼å›æµ‹ç´¯è®¡æ”¶ç›Šå¯¹æ¯”]")
        
        if not dfd.empty:
            dfd_plot = dfd.copy()
            dfd_plot['date'] = pd.to_datetime(dfd_plot['date'])
            dfd_plot.set_index("date", inplace=True)
            
            show_cumulative_returns(
                dfd_plot, 
                fig_title=f"{title_prefix}ä¸åŒäº¤æ˜“ä»·æ ¼ç´¯è®¡æ”¶ç›Šå¯¹æ¯”"
            )
        else:
            st.warning("æ²¡æœ‰æœ‰æ•ˆçš„æ”¶ç›Šç‡æ•°æ®ç”¨äºç»˜åˆ¶å›¾è¡¨")
    
    logger.info(f"ä»·æ ¼æ•æ„Ÿæ€§åˆ†æå®Œæˆï¼Œå…±å¤„ç† {len(rows)} ä¸ªäº¤æ˜“ä»·æ ¼")
    return dfr, dfd


def price_sensitive_summary(dfr, top_n=3):
    """ç”Ÿæˆä»·æ ¼æ•æ„Ÿæ€§åˆ†ææ‘˜è¦
    
    :param dfr: pd.DataFrame, show_price_sensitive è¿”å›çš„ç»Ÿè®¡ç»“æœ
    :param top_n: int, æ˜¾ç¤ºå‰Nä¸ªæœ€ä½³äº¤æ˜“ä»·æ ¼ï¼Œé»˜è®¤3
    """
    if dfr is None or dfr.empty:
        st.warning("æ²¡æœ‰å¯ç”¨çš„åˆ†æç»“æœ")
        return
    
    with st.container(border=True):
        st.markdown("##### :blue[ä»·æ ¼æ•æ„Ÿæ€§åˆ†ææ‘˜è¦]")
        
        # æŒ‰å¹´åŒ–æ”¶ç›Šç‡æ’åº
        if "å¹´åŒ–" in dfr.columns:
            dfr_sorted = dfr.sort_values("å¹´åŒ–", ascending=False)
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("æœ€ä½³å¹´åŒ–æ”¶ç›Šç‡", 
                         f"{dfr_sorted.iloc[0]['å¹´åŒ–']:.2%}", 
                         f"äº¤æ˜“ä»·æ ¼: {dfr_sorted.iloc[0]['äº¤æ˜“ä»·æ ¼']}")
            
            with col2:
                if "å¤æ™®" in dfr.columns:
                    best_sharpe = dfr.loc[dfr["å¤æ™®"].idxmax()]
                    st.metric("æœ€ä½³å¤æ™®æ¯”ç‡", 
                             f"{best_sharpe['å¤æ™®']:.2f}", 
                             f"äº¤æ˜“ä»·æ ¼: {best_sharpe['äº¤æ˜“ä»·æ ¼']}")
            
            with col3:
                if "æœ€å¤§å›æ’¤" in dfr.columns:
                    min_drawdown = dfr.loc[dfr["æœ€å¤§å›æ’¤"].idxmin()]
                    st.metric("æœ€å°å›æ’¤", 
                             f"{min_drawdown['æœ€å¤§å›æ’¤']:.2%}", 
                             f"äº¤æ˜“ä»·æ ¼: {min_drawdown['äº¤æ˜“ä»·æ ¼']}")
            
            # æ˜¾ç¤ºå‰Nä¸ªæœ€ä½³äº¤æ˜“ä»·æ ¼
            st.markdown(f"**å‰{top_n}ä¸ªæœ€ä½³äº¤æ˜“ä»·æ ¼ï¼ˆæŒ‰å¹´åŒ–æ”¶ç›Šç‡ï¼‰ï¼š**")
            top_prices = dfr_sorted.head(top_n)
            for i, (_, row) in enumerate(top_prices.iterrows(), 1):
                st.write(f"{i}. {row['äº¤æ˜“ä»·æ ¼']}: å¹´åŒ– {row['å¹´åŒ–']:.2%}, å¤æ™® {row.get('å¤æ™®', 'N/A'):.2f if pd.notna(row.get('å¤æ™®')) else 'N/A'}")
        
        # ä»·æ ¼æ•æ„Ÿæ€§è¯„ä¼°
        if len(dfr) > 1 and "å¹´åŒ–" in dfr.columns:
            annual_returns = dfr["å¹´åŒ–"].values
            sensitivity_score = (annual_returns.max() - annual_returns.min()) / annual_returns.mean()
            
            st.markdown("**æ•æ„Ÿæ€§è¯„ä¼°ï¼š**")
            if sensitivity_score < 0.1:
                st.success(f"ğŸŸ¢ ç­–ç•¥å¯¹ä»·æ ¼æ‰§è¡Œä¸æ•æ„Ÿ (æ•æ„Ÿåº¦: {sensitivity_score:.2%})")
            elif sensitivity_score < 0.3:
                st.warning(f"ğŸŸ¡ ç­–ç•¥å¯¹ä»·æ ¼æ‰§è¡Œä¸­ç­‰æ•æ„Ÿ (æ•æ„Ÿåº¦: {sensitivity_score:.2%})")
            else:
                st.error(f"ğŸ”´ ç­–ç•¥å¯¹ä»·æ ¼æ‰§è¡Œé«˜åº¦æ•æ„Ÿ (æ•æ„Ÿåº¦: {sensitivity_score:.2%})") 